/**
 * AIsBreaker API
 * Specification of the AIsBreaker API. This API is used to access AI services.
 *
 * OpenAPI spec version: 0.6.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { InputMessage } from '../models/InputMessage';
import { RequestMedia } from '../models/RequestMedia';
import { RequestOptions } from '../models/RequestOptions';
import { HttpFile } from '../http/http';

/**
* Send a message to the AI service and get the response.
*/
export class ConversationRequest {
    /**
    * List of messages (prompts, media, ...) to send to the AI service for the conversation specified in `conversation_state`.
    */
    'messages': Array<InputMessage>;
    /**
    * The value presents the conversation, i.e. the mistory of all (relevant) messages of the conversation. Not set for the first call of a conversation. The `conversation_state` value is returned by previous call of the same conversation. The value is opaque to the client, it could be e.g. a conversation ID or the full conversation state as base64-encoded JSON string or ...
    */
    'conversationState'?: string;
    'requestMedia'?: RequestMedia;
    '_requestOptions'?: RequestOptions;
    /**
    * Service implementation specific opts. Try to avoid using them because they are NOT portable!!!
    */
    'internOptions'?: any | null;
    /**
    * A unique identifier representing the end-user, which can help the AI service to monitor and detect abuse. ( e.g. https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids ) the value is opaque to the API. Do not use emails or other personally identifiable information (PII); instead use temporary identifies or hashed or encrypted values. ALternatively, this field can also be used for tracing and debugging purposes.
    */
    'clientUser'?: string;
    /**
    * If set to true, partial message deltas will be sent, like in ChatGPT.  Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE]
    */
    'streamProgress'?: boolean;

    static readonly discriminator: string | undefined = undefined;

    static readonly attributeTypeMap: Array<{name: string, baseName: string, type: string, format: string}> = [
        {
            "name": "messages",
            "baseName": "messages",
            "type": "Array<InputMessage>",
            "format": ""
        },
        {
            "name": "conversationState",
            "baseName": "conversation_state",
            "type": "string",
            "format": ""
        },
        {
            "name": "requestMedia",
            "baseName": "request_media",
            "type": "RequestMedia",
            "format": ""
        },
        {
            "name": "_requestOptions",
            "baseName": "request_options",
            "type": "RequestOptions",
            "format": ""
        },
        {
            "name": "internOptions",
            "baseName": "intern_options",
            "type": "any",
            "format": ""
        },
        {
            "name": "clientUser",
            "baseName": "client_user",
            "type": "string",
            "format": ""
        },
        {
            "name": "streamProgress",
            "baseName": "stream_progress",
            "type": "boolean",
            "format": ""
        }    ];

    static getAttributeTypeMap() {
        return ConversationRequest.attributeTypeMap;
    }

    public constructor() {
    }
}

